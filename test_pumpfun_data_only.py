#!/usr/bin/env python3
"""
Quick test of Pump.fun data fetching without Claude API.
This demonstrates the live data integration is working.
"""

import os
import sys
from dotenv import load_dotenv

# Load environment variables
load_dotenv()

# Force debug mode
os.environ["DEBUG"] = "True"

from src.utils.logger import setup_logger, get_logger
from src.api.pumpfun_client import PumpFunClient

setup_logger()
logger = get_logger(__name__)


def main():
    """Test Pump.fun data fetching only."""

    print("\n" + "="*70)
    print("ğŸ¸ Pump.fun Live Data Test (No Claude API Required)")
    print("="*70)
    print()

    client = PumpFunClient()

    # Test 1: Trending tokens
    print("ğŸ“ˆ FETCHING TRENDING TOKENS...")
    print("-"*70)
    trending = client.get_trending_tokens(limit=5)

    if trending:
        print(f"âœ“ Found {len(trending)} trending tokens:\n")
        for i, token in enumerate(trending, 1):
            name = token.get('name', 'Unknown')
            symbol = token.get('symbol', '???')
            volume = token.get('volume_24h', 0)
            price_change = token.get('price_change_24h', 0)

            change_emoji = "ğŸ“ˆ" if price_change > 0 else "ğŸ“‰"
            print(f"  {i}. {name} (${symbol})")
            print(f"     24h Volume: ${volume:,.0f}")
            print(f"     24h Change: {price_change:+.2f}% {change_emoji}")
            print()
    else:
        print("âš  No trending tokens found (using fallback)")
        print()

    # Test 2: Current narrative
    print("\nğŸ¯ DETECTING CURRENT META...")
    print("-"*70)
    narrative = client.get_trending_narrative()
    print(f"âœ“ Current narrative: {narrative}")
    print()

    # Test 3: Platform stats
    print("\nğŸ“Š PLATFORM STATISTICS...")
    print("-"*70)
    stats = client.get_pump_fun_stats()
    print(f"âœ“ Total tokens: {stats.get('total_tokens', 'N/A')}")
    print(f"âœ“ 24h volume: {stats.get('volume_24h', 'N/A')}")
    print(f"âœ“ 24h trades: {stats.get('trades_24h', 'N/A')}")
    print(f"âœ“ Avg token volume: {stats.get('avg_token_volume', 'N/A')}")
    print()

    # Test 4: Rug detection
    print("\nğŸš¨ DETECTING SUSPICIOUS ACTIVITY...")
    print("-"*70)
    rugs = client.detect_rugs(hours=24)
    print(f"âœ“ Found {len(rugs)} suspicious tokens in last 24h")

    if rugs:
        print("\nSuspicious tokens:")
        for rug in rugs[:3]:  # Show first 3
            name = rug.get('name', 'Unknown')
            symbol = rug.get('symbol', '???')
            price_change = rug.get('price_change_24h', 0)
            print(f"  â€¢ {name} (${symbol}) - {price_change:+.2f}% ğŸ“‰")
    print()

    # Test 5: Comprehensive context
    print("\nğŸ¨ BUILDING CONTEXT FOR CONTENT GENERATION...")
    print("-"*70)
    context = client.get_context_for_content()

    print("âœ“ Context built successfully:")
    print(f"  â€¢ Trending tokens: {len(context.get('trending_tokens', []))}")
    print(f"  â€¢ Recent launches: {len(context.get('recent_launches', []))}")
    print(f"  â€¢ Current narrative: {context.get('narrative', 'unknown')}")
    print(f"  â€¢ Suspicious activity: {len(context.get('suspicious_activity', []))}")
    print()

    # Test 6: Show what Pepe would see
    print("\nğŸ’¬ EXAMPLE CONTEXT PEPE WOULD RECEIVE...")
    print("-"*70)

    context_str = "Current Pump.fun ecosystem context:\n"

    if context.get('narrative'):
        context_str += f"- Current meta: {context['narrative']}\n"

    trending_top = context.get('trending_tokens', [])[:3]
    if trending_top:
        context_str += "- Trending tokens:\n"
        for token in trending_top:
            name = token.get('name', 'Unknown')
            symbol = token.get('symbol', '???')
            context_str += f"  * {name} (${symbol})\n"

    stats = context.get('platform_stats', {})
    if stats:
        context_str += f"- Platform activity: {stats.get('volume_24h', 'N/A')} 24h volume\n"

    suspicious = context.get('suspicious_activity', [])
    if suspicious:
        context_str += f"- Suspicious activity: {len(suspicious)} potential rugs detected\n"

    print(context_str)

    # Summary
    print("\n" + "="*70)
    print("âœ… LIVE DATA INTEGRATION TEST COMPLETE")
    print("="*70)
    print()
    print("Key Findings:")
    print("  âœ“ DexScreener API is responding (no 530 errors!)")
    print("  âœ“ Trending tokens are being fetched")
    print("  âœ“ Platform stats are calculated")
    print("  âœ“ Narrative detection is working")
    print("  âœ“ Rug detection heuristics are running")
    print("  âœ“ Context building is functional")
    print()
    print("What this means:")
    print("  â€¢ Pepe can now reference REAL trending tokens in tweets")
    print("  â€¢ Ecosystem data is available for all content types")
    print("  â€¢ The agent works even if DexScreener fails (fallback mode)")
    print()
    print("Next step:")
    print("  Add your ANTHROPIC_API_KEY to .env to test full content generation")
    print("  Then run: python test_pumpfun_live.py")
    print()
    print("ğŸ¸ gm anon, the frog knows what's trending now")
    print()

    return 0


if __name__ == "__main__":
    sys.exit(main())
